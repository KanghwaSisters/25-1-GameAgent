{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 딥러닝 실습 과제 2주차 - CNN을 활용하여 보드 전체를 입력받아 9칸 상태 예측\n",
        "\n",
        "다음  세 가지 활동을 해봅시다.\n",
        "\n",
        "01. **모델 설계**: CNN 기반 분류 모델 활용\n",
        "02. **손실 함수 정의**: 각 칸에 대해 3-클래스 분류\n",
        "03. **학습 및 평가**: 시각화 함수, 정확도 측정, confusion matrix 등"
      ],
      "metadata": {
        "id": "_vECysj7UNoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTTDataset.zip을 불러와 문제에서 요하는 코드를 구현하세요.\n",
        "\n",
        "💡 **데이터 구조**  \n",
        "- **`image_black`** : 이미지 데이터  \n",
        "- **`labels`** : 타겟 데이터  "
      ],
      "metadata": {
        "id": "s3_fdD7Y2iY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BJKliYMHk2q",
        "outputId": "da64a4a6-b2f8-42ec-e18e-f7e2521e5ca7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "BhRH2q-fV8lc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. 클래스\n",
        "정의한 클래스를 이용해 실행해 주세요."
      ],
      "metadata": {
        "id": "MCpJfLtnagvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        \"\"\"\n",
        "        틱택토 데이터셋을 PyTorch Dataset 형태로 변환.\n",
        "        :param image_paths: 이미지 파일 경로 리스트\n",
        "        :param label_paths: 레이블 JSON 파일 경로 리스트\n",
        "        :param transform: 이미지 전처리 변환\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.data = self._load_data()\n",
        "\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" 이미지 & 레이블 로드 \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # 이미지를 흑백(Grayscale)로 변환\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" 대신 \"L\" 사용\n",
        "\n",
        "            # JSON 레이블 로드\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # 레이블을 숫자로 변환 (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" 데이터셋 크기 반환 \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" 데이터셋에서 idx 번째 샘플(이미지 & 레이블)을 가져오는 역할 \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Ymwd8gfCYHiq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축 파일 풀기\n",
        "zip_path = \"/content/drive/MyDrive/TTTDataset.zip\"\n",
        "extract_path = \"/content/TTTDataset\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    !unzip -q \"{zip_path}\" -d \"/content/\"\n",
        "    print(\" 압축 해제 완료!\")\n",
        "else:\n",
        "    print(\" 이미 압축이 풀려 있으므로 건너뜁니다.\")"
      ],
      "metadata": {
        "id": "kYqOL0NrIfEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcd5256-8984-41fc-d51e-1de617d6e705"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 이미 압축이 풀려 있으므로 건너뜁니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 및 레이블 디렉토리 경로 설정\n",
        "image_dir = \"/content/TTTDataset/image_black\"\n",
        "label_dir = \"/content/TTTDataset/labels\"\n",
        "\n",
        "# 이미지와 라벨 파일 자동 수집 (확장자가 .jpg 또는 .JPG인 점 확인)\n",
        "image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")) +\n",
        "                     glob.glob(os.path.join(image_dir, \"*.JPG\")))\n",
        "\n",
        "label_paths = sorted(glob.glob(os.path.join(label_dir, \"*.json\")))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(), # 픽셀값을 텐서로 변환 (0~1로 자동 스케일링됨)\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Dataset 생성\n",
        "dataset = TTTDataset(image_paths, label_paths, transform=transform)\n",
        "\n",
        "# 전체 데이터 크기 기준 분할 비율 설정 (예: 70% train, 15% val, 15% test)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# 데이터 분할\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# 각각에 대한 데이터로더 생성\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "Ue-8ZaunXd1q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 모델 설계: CNN 기반 분류 모델 활용\n",
        "- 입력: 틱택토 보드 전체 이미지 (예: 128x128)\n",
        "- 출력: 9개의 상태(각 칸마다 O, X, blank 중 하나)"
      ],
      "metadata": {
        "id": "seQgBNd9aZNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8KvefRQ4XhtC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # super(): CNN class의 부모 class인 nn.Module을 초기화\n",
        "        super(TicTacToeCNN, self).__init__()\n",
        "\n",
        "        # 첫번째 층\n",
        "        self.layer1 = nn.Sequential(\n",
        "            # Convolution Layer: 1채널 입력을 32채널 특징맵(feature map)으로 변환\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # (B, 1, 128, 128) → (B, 16, 128, 128)\n",
        "            # 비선형 활성함수\n",
        "            nn.ReLU(),\n",
        "            # Pooling Layer: 크기 절반으로 축소\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))            # (B, 32, 64, 64)\n",
        "\n",
        "        # 두번째 층\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))              # (B, 64, 32, 32)\n",
        "\n",
        "        # 세번째 층\n",
        "        self.layer3= nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))    # (B, 128, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Fully-connected Layer: 칸 별로 3-클래스 점수 출력\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(128, 256),   # 중간 hidden layer 추가\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 9 * 3))   # 128차원 백터 -> 27개 출력 (9칸 × 각 칸 당 3-클래스)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)              # (B, 16, 64, 64)\n",
        "        x = self.layer2(x)              # (B, 32, 32, 32)\n",
        "        x = self.layer3(x)              # (B, 64, 1, 1)\n",
        "        x = x.view(x.size(0), -1)       # (B, 64)\n",
        "        x = self.fc_layer(x)            # (B, 27)\n",
        "        return x.view(-1, 9, 3)         # (B, 9, 3)"
      ],
      "metadata": {
        "id": "misG2sDL1pj1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 손실 함수 정의: 각 칸에 대해 3-클래스 분류\n",
        "- 다중 클래스 분류이므로 CrossEntropyLoss 사용 가능\n",
        "- 9개 칸을 각각 분류하는 방식으로 모델 구성"
      ],
      "metadata": {
        "id": "DYVGt8R27tXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델 객체 선언\n",
        "model = TicTacToeCNN().to(device)\n",
        "\n",
        "# 손실 함수 정의 (다중 클래스 분류)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 최적화 알고리즘 정의\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "aHRXEG9NB4kX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 학습 및 평가: 시각화 함수, 정확도 측정, confusion matrix 등\n",
        "- 학습 데이터로 모델을 훈련하고, 정확도 측정\n",
        "- 예측이 잘 되는지 시각화하여 분석"
      ],
      "metadata": {
        "id": "ugSpuxB27va_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수 정의\n",
        "def preprocess_batch(images, labels):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # CrossEntropy는 정수 클래스 (0, 1, 2)를 기대함\n",
        "    target = (labels + 1).to(torch.int64)   # -1 → 0, 0 → 1, 1 → 2로 정수형 변환\n",
        "    return images, target"
      ],
      "metadata": {
        "id": "MO0MYs9MwHNl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 함수 정의\n",
        "def evaluate(loader):  # train_loader, val_loader, test_loader 중 하나를 넘길 수 있음\n",
        "    model.eval()\n",
        "    # 예측이 맞은 칸 수\n",
        "    correct = 0\n",
        "    # 전체 칸 수\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, target = preprocess_batch(images, labels)\n",
        "            # 모델에 이미지 삽입하여 예측 수행\n",
        "            outputs = model(images)  # (B, 9, 3)\n",
        "            # 각 칸마다 3-클래스 중 가장 높은 점수를 선택\n",
        "            preds = outputs.argmax(dim=2)  # (B, 9)\n",
        "            correct += (preds == target).sum().item()\n",
        "            total += target.numel()\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "Sq_Dv7rO16lx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    # 누적 손실 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, target = preprocess_batch(images, labels)\n",
        "\n",
        "        optimizer.zero_grad() # 기울기 초기화\n",
        "        outputs = model(images)  # (B, 9, 3)\n",
        "        loss = criterion(outputs.view(-1, 3), target.view(-1)) # 손실 계산\n",
        "        loss.backward() # 역전파\n",
        "        optimizer.step() # 가중치 업데이트\n",
        "        total_loss += loss.item() # 손실 누적\n",
        "\n",
        "    # 1 epoch마다 검증 정확도 평가\n",
        "    val_acc = evaluate(val_loader)\n",
        "    print(f\"[Epoch {epoch+1:02d}] Loss: {total_loss:.4f} | Val Accuracy: {val_acc:.2%}\")"
      ],
      "metadata": {
        "id": "b2xM8ol5Xlj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29361f4-55c8-4abc-ab39-1aadc6623af0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] Loss: 10.9433 | Val Accuracy: 36.32%\n",
            "[Epoch 02] Loss: 10.8532 | Val Accuracy: 36.65%\n",
            "[Epoch 03] Loss: 10.8276 | Val Accuracy: 37.65%\n",
            "[Epoch 04] Loss: 10.8050 | Val Accuracy: 37.15%\n",
            "[Epoch 05] Loss: 10.7515 | Val Accuracy: 37.65%\n",
            "[Epoch 06] Loss: 10.6839 | Val Accuracy: 37.65%\n",
            "[Epoch 07] Loss: 10.5424 | Val Accuracy: 40.96%\n",
            "[Epoch 08] Loss: 10.5457 | Val Accuracy: 40.13%\n",
            "[Epoch 09] Loss: 10.5051 | Val Accuracy: 37.15%\n",
            "[Epoch 10] Loss: 10.4569 | Val Accuracy: 39.14%\n",
            "[Epoch 11] Loss: 10.3430 | Val Accuracy: 42.12%\n",
            "[Epoch 12] Loss: 10.2234 | Val Accuracy: 42.45%\n",
            "[Epoch 13] Loss: 10.1389 | Val Accuracy: 42.62%\n",
            "[Epoch 14] Loss: 10.0780 | Val Accuracy: 42.95%\n",
            "[Epoch 15] Loss: 10.0507 | Val Accuracy: 42.79%\n",
            "[Epoch 16] Loss: 9.9854 | Val Accuracy: 42.12%\n",
            "[Epoch 17] Loss: 10.0555 | Val Accuracy: 42.62%\n",
            "[Epoch 18] Loss: 10.0311 | Val Accuracy: 43.45%\n",
            "[Epoch 19] Loss: 9.8657 | Val Accuracy: 43.78%\n",
            "[Epoch 20] Loss: 9.8835 | Val Accuracy: 45.44%\n",
            "[Epoch 21] Loss: 9.8677 | Val Accuracy: 43.95%\n",
            "[Epoch 22] Loss: 9.8022 | Val Accuracy: 43.45%\n",
            "[Epoch 23] Loss: 9.7545 | Val Accuracy: 44.94%\n",
            "[Epoch 24] Loss: 9.6655 | Val Accuracy: 44.78%\n",
            "[Epoch 25] Loss: 9.6310 | Val Accuracy: 46.93%\n",
            "[Epoch 26] Loss: 9.5890 | Val Accuracy: 49.42%\n",
            "[Epoch 27] Loss: 9.5020 | Val Accuracy: 46.93%\n",
            "[Epoch 28] Loss: 9.6441 | Val Accuracy: 51.08%\n",
            "[Epoch 29] Loss: 9.4650 | Val Accuracy: 49.75%\n",
            "[Epoch 30] Loss: 9.3966 | Val Accuracy: 49.75%\n",
            "[Epoch 31] Loss: 9.3452 | Val Accuracy: 50.08%\n",
            "[Epoch 32] Loss: 9.3121 | Val Accuracy: 51.91%\n",
            "[Epoch 33] Loss: 9.2103 | Val Accuracy: 49.09%\n",
            "[Epoch 34] Loss: 9.1801 | Val Accuracy: 51.58%\n",
            "[Epoch 35] Loss: 9.1405 | Val Accuracy: 49.59%\n",
            "[Epoch 36] Loss: 8.9983 | Val Accuracy: 50.41%\n",
            "[Epoch 37] Loss: 8.9782 | Val Accuracy: 51.24%\n",
            "[Epoch 38] Loss: 8.9545 | Val Accuracy: 52.57%\n",
            "[Epoch 39] Loss: 8.9104 | Val Accuracy: 50.58%\n",
            "[Epoch 40] Loss: 8.9034 | Val Accuracy: 50.08%\n",
            "[Epoch 41] Loss: 8.8127 | Val Accuracy: 50.41%\n",
            "[Epoch 42] Loss: 8.7815 | Val Accuracy: 50.41%\n",
            "[Epoch 43] Loss: 8.7703 | Val Accuracy: 50.75%\n",
            "[Epoch 44] Loss: 8.7851 | Val Accuracy: 51.41%\n",
            "[Epoch 45] Loss: 8.7249 | Val Accuracy: 52.07%\n",
            "[Epoch 46] Loss: 8.7305 | Val Accuracy: 49.75%\n",
            "[Epoch 47] Loss: 8.7019 | Val Accuracy: 51.08%\n",
            "[Epoch 48] Loss: 8.7349 | Val Accuracy: 48.09%\n",
            "[Epoch 49] Loss: 8.7746 | Val Accuracy: 49.75%\n",
            "[Epoch 50] Loss: 8.6842 | Val Accuracy: 50.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = evaluate(test_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMkd_0uxqNaw",
        "outputId": "273e6e8a-8f5b-4ab8-ff43-4555e49ffc6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 50.56%\n"
          ]
        }
      ]
    }
  ]
}