{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GridWorldEnvironment\n",
        "```py\n",
        "start_point = (0,0)\n",
        "end_point = (4,4)\n",
        "gridworld_size = (5,5)\n",
        "env = GridWorldEnvironment(start_point, end_point, grid_world_size)\n",
        "```"
      ],
      "metadata": {
        "id": "hoXHmyZi5t5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original Code"
      ],
      "metadata": {
        "id": "dm89RWca6WOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "class GridWorldEnvironment:\n",
        "    def __init__(self, start_point:Tuple, end_point:Tuple, grid_world_size:Tuple):\n",
        "        # 시작점과 끝점을 받는다.\n",
        "        self.start_point = start_point\n",
        "        self.end_point = end_point if end_point != (-1,-1) else (grid_world_size[0] + end_point[0],\n",
        "                                                                 grid_world_size[1] + end_point[1])\n",
        "\n",
        "        # 그리드 월드의 규격을 받는다.\n",
        "        self.width, self.height = grid_world_size\n",
        "\n",
        "        # action dictionary\n",
        "        self.action_space = ['up', 'down', 'left', 'right']\n",
        "        self.num_actions = len(self.action_space)\n",
        "        self.actions = {'up':(-1,0),\n",
        "                        'down':(1,0),\n",
        "                        'left':(0,-1),\n",
        "                        'right':(0,1) }\n",
        "\n",
        "        # 상태 : 좌표로 나타남\n",
        "        self.traces = []\n",
        "\n",
        "        # total states\n",
        "        self.total_states = []\n",
        "        for x in range(self.width):\n",
        "            for y in range(self.height):\n",
        "                self.total_states.append((x,y))\n",
        "\n",
        "        # reward\n",
        "        self.reward = np.zeros(shape=(self.height, self.width)).tolist()\n",
        "        self.reward[end_point[0]][end_point[1]] = 1\n",
        "\n",
        "    def render(self):\n",
        "        # 그리드 월드의 상태를 출력한다.\n",
        "        self.grid_world = np.full(shape=(self.height, self.width), fill_value=\".\").tolist()\n",
        "\n",
        "        last_point = self.traces[-1] # 에이전트가 가장 마지막에 있었던 위치\n",
        "        traces = list(set(self.traces)) # 중복된 값을 삭제하기 위함\n",
        "        for trace in traces:\n",
        "            self.grid_world[trace[0]][trace[1]] = \"X\"\n",
        "\n",
        "        self.grid_world[self.start_point[0]][self.start_point[1]] = \"S\" # start point\n",
        "        self.grid_world[self.end_point[0]][self.end_point[1]] = \"G\" # end point\n",
        "        self.grid_world[last_point[0]][last_point[1]] = \"A\" # 현재 에이전트의 위치\n",
        "\n",
        "        # string으로 출력한다.\n",
        "        grid = \"\"\n",
        "\n",
        "        for i in range(self.height):\n",
        "            for j in range(self.width):\n",
        "                grid += self.grid_world[i][j]+\" \"\n",
        "            grid += \"\\n\"\n",
        "\n",
        "        print(grid)\n",
        "\n",
        "    def get_reward(self, state, action_idx):\n",
        "        next_state = self.state_after_action(state, action_idx)\n",
        "        return self.reward[next_state[0]][next_state[1]]\n",
        "\n",
        "    def state_after_action(self, state, action_idx:int):\n",
        "        action = self.action_space[action_idx]\n",
        "        row_movement, col_movement = self.actions[action]\n",
        "\n",
        "        # action에 따라 에이전트 이동\n",
        "        next_state = (state[0]+row_movement, state[1]+col_movement)\n",
        "        next_state = self.check_boundary(next_state)\n",
        "\n",
        "        return next_state\n",
        "\n",
        "    def check_boundary(self, state):\n",
        "        state = list(state)\n",
        "        state[0] = (0 if state[0] < 0 else self.height - 1 if state[0] > self.height - 1 else state[0])\n",
        "        state[1] = (0 if state[1] < 0 else self.width - 1 if state[1] > self.width - 1 else state[1])\n",
        "        return tuple(state)"
      ],
      "metadata": {
        "id": "wiEaAqK76G9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep SARSA Class"
      ],
      "metadata": {
        "id": "Gvc0Jr9m6xZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = GridWorldEnvironment(start_point=(0,0), #위 환경 클래스를 상속 받아 `env.render` 코드를 구현\n",
        "                           end_point=(4,4),\n",
        "                           grid_world_size=(5,5))"
      ],
      "metadata": {
        "id": "DNnwj-jO23E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLYRJG0y6ypp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "7jW6ivs16zHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Deep SARSA**를 이용해 그리드 월드 학습시키기  \n",
        "- 학습 지표 시각화 (에피소드마다 에이전트의 이동 횟수 시각화)"
      ],
      "metadata": {
        "id": "Kpj3a2xf7Pkz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzJHw6KJ60wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "biV8MCMK_bam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-learning Class"
      ],
      "metadata": {
        "id": "8lcAueBB_kzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = GridWorldEnvironment(start_point=(0,0), #위 환경 클래스를 상속 받아 `env.render` 코드를 구현\n",
        "                           end_point=(4,4),\n",
        "                           grid_world_size=(5,5))"
      ],
      "metadata": {
        "id": "lgA9GtWJIcqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRQy6jbP_kzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "eQJyyQgX_kzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Q-learning**를 이용해 그리드 월드 학습시키기  \n",
        "- 학습 지표 시각화 (에피소드마다 에이전트의 이동 횟수 시각화)"
      ],
      "metadata": {
        "id": "SHn74SR5_kzc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dYx--quI_kzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}