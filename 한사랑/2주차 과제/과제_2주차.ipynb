{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vECysj7UNoM"
      },
      "source": [
        "### ë”¥ëŸ¬ë‹ ì‹¤ìŠµ ê³¼ì œ 2ì£¼ì°¨ - CNNì„ í™œìš©í•˜ì—¬ ë³´ë“œ ì „ì²´ë¥¼ ì…ë ¥ë°›ì•„ 9ì¹¸ ìƒíƒœ ì˜ˆì¸¡\n",
        "\n",
        "ë‹¤ìŒ  ì„¸ ê°€ì§€ í™œë™ì„ í•´ë´…ì‹œë‹¤.\n",
        "\n",
        "01. **ëª¨ë¸ ì„¤ê³„**: CNN ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ í™œìš©\n",
        "02. **ì†ì‹¤ í•¨ìˆ˜ ì •ì˜**: ê° ì¹¸ì— ëŒ€í•´ 3-í´ë˜ìŠ¤ ë¶„ë¥˜\n",
        "03. **í•™ìŠµ ë° í‰ê°€**: ì‹œê°í™” í•¨ìˆ˜, ì •í™•ë„ ì¸¡ì •, confusion matrix ë“±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3_fdD7Y2iY4"
      },
      "source": [
        "TTTDataset.zipì„ ë¶ˆëŸ¬ì™€ ë¬¸ì œì—ì„œ ìš”í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
        "\n",
        "ğŸ’¡ **ë°ì´í„° êµ¬ì¡°**  \n",
        "- **`image_black`** : ì´ë¯¸ì§€ ë°ì´í„°  \n",
        "- **`labels`** : íƒ€ê²Ÿ ë°ì´í„°  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhRH2q-fV8lc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCpJfLtnagvV"
      },
      "source": [
        "#### 00. í´ë˜ìŠ¤\n",
        "ì •ì˜í•œ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ì‹¤í–‰í•´ ì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymwd8gfCYHiq"
      },
      "outputs": [],
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        \"\"\"\n",
        "        í‹±íƒí†  ë°ì´í„°ì…‹ì„ PyTorch Dataset í˜•íƒœë¡œ ë³€í™˜.\n",
        "        :param image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param label_paths: ë ˆì´ë¸” JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.data = self._load_data()\n",
        "\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # ì´ë¯¸ì§€ë¥¼ í‘ë°±(Grayscale)ë¡œ ë³€í™˜\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" ëŒ€ì‹  \"L\" ì‚¬ìš©\n",
        "\n",
        "            # JSON ë ˆì´ë¸” ë¡œë“œ\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" ë°ì´í„°ì…‹ í¬ê¸° ë°˜í™˜ \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" ë°ì´í„°ì…‹ì—ì„œ idx ë²ˆì§¸ ìƒ˜í”Œ(ì´ë¯¸ì§€ & ë ˆì´ë¸”)ì„ ê°€ì ¸ì˜¤ëŠ” ì—­í•  \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seQgBNd9aZNk"
      },
      "source": [
        "#### 01. ëª¨ë¸ ì„¤ê³„: CNN ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ í™œìš©\n",
        "- ì…ë ¥: í‹±íƒí†  ë³´ë“œ ì „ì²´ ì´ë¯¸ì§€ (ì˜ˆ: 128x128)\n",
        "- ì¶œë ¥: 9ê°œì˜ ìƒíƒœ(ê° ì¹¸ë§ˆë‹¤ O, X, blank ì¤‘ í•˜ë‚˜)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue-8ZaunXd1q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYVGt8R27tXu"
      },
      "source": [
        "#### 02. ì†ì‹¤ í•¨ìˆ˜ ì •ì˜: ê° ì¹¸ì— ëŒ€í•´ 3-í´ë˜ìŠ¤ ë¶„ë¥˜\n",
        "- ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì´ë¯€ë¡œ CrossEntropyLoss ì‚¬ìš© ê°€ëŠ¥\n",
        "- 9ê°œ ì¹¸ì„ ê°ê° ë¶„ë¥˜í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ êµ¬ì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KvefRQ4XhtC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSpuxB27va_"
      },
      "source": [
        "#### 03. í•™ìŠµ ë° í‰ê°€: ì‹œê°í™” í•¨ìˆ˜, ì •í™•ë„ ì¸¡ì •, confusion matrix ë“±\n",
        "- í•™ìŠµ ë°ì´í„°ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³ , ì •í™•ë„ ì¸¡ì •\n",
        "- ì˜ˆì¸¡ì´ ì˜ ë˜ëŠ”ì§€ ì‹œê°í™”í•˜ì—¬ ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2xM8ol5Xlj7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
