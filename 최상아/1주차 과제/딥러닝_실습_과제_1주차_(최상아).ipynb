{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ë”¥ëŸ¬ë‹ ì‹¤ìŠµ ê³¼ì œ 1ì£¼ì°¨ - ë°ì´í„° ì „ì²˜ë¦¬\n",
        "\n",
        "ë‹¤ìŒ ì„¸ ê°€ì§€ í™œë™ì„ í•´ë´…ì‹œë‹¤.\n",
        "\n",
        "01. **ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ**: JSON íŒŒì¼ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PyTorch Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "02. **ì´ë¯¸ì§€ ì „ì²˜ë¦¬**: í¬ê¸° ì¡°ì •, ì •ê·œí™”\n",
        "03. **í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• **\n"
      ],
      "metadata": {
        "id": "_vECysj7UNoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTTDataset.zipì„ ë¶ˆëŸ¬ì™€ ë¬¸ì œì—ì„œ ìš”í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
        "\n",
        "ğŸ’¡ **ë°ì´í„° êµ¬ì¡°**  \n",
        "- **`image_black`** : ì´ë¯¸ì§€ ë°ì´í„°  \n",
        "- **`labels`** : íƒ€ê²Ÿ ë°ì´í„°  "
      ],
      "metadata": {
        "id": "s3_fdD7Y2iY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "BhRH2q-fV8lc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. í´ë˜ìŠ¤\n",
        "ì •ì˜í•œ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ì‹¤í–‰í•´ ì£¼ì„¸ìš”."
      ],
      "metadata": {
        "id": "MCpJfLtnagvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        \"\"\"\n",
        "        í‹±íƒí†  ë°ì´í„°ì…‹ì„ PyTorch Dataset í˜•íƒœë¡œ ë³€í™˜.\n",
        "        :param image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param label_paths: ë ˆì´ë¸” JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.data = self._load_data()\n",
        "\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # ì´ë¯¸ì§€ë¥¼ í‘ë°±(Grayscale)ë¡œ ë³€í™˜\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" ëŒ€ì‹  \"L\" ì‚¬ìš©\n",
        "\n",
        "            # JSON ë ˆì´ë¸” ë¡œë“œ\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" ë°ì´í„°ì…‹ í¬ê¸° ë°˜í™˜ \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" ë°ì´í„°ì…‹ì—ì„œ idx ë²ˆì§¸ ìƒ˜í”Œ(ì´ë¯¸ì§€ & ë ˆì´ë¸”)ì„ ê°€ì ¸ì˜¤ëŠ” ì—­í•  \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Ymwd8gfCYHiq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ: JSON íŒŒì¼ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PyTorch Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜"
      ],
      "metadata": {
        "id": "seQgBNd9aZNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "\n",
        "      image_dir = '/Users/sowcel/Downloads/TTTDataset/image_black'\n",
        "      label_dir = '/Users/sowcel/Downloads/TTTDataset/labels'\n",
        "\n",
        "      self.image_paths = image_paths\n",
        "      self.label_paths = label_paths\n",
        "      self.transform = transform\n",
        "      self.data = self._load_data()\n",
        "\n",
        "    def get_image_paths(image_dir):\n",
        "      valid_extentions = ('.jpg', '.JPG')\n",
        "      image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(valid_extentions)]\n",
        "      return image_paths\n",
        "\n",
        "    def get_label_paths(label_dir):\n",
        "      valid_extentions = ('.json')\n",
        "      label_paths = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(valid_extentions)]\n",
        "      return label_paths\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # ì´ë¯¸ì§€ë¥¼ í‘ë°±(Grayscale)ë¡œ ë³€í™˜\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" ëŒ€ì‹  \"L\" ì‚¬ìš©\n",
        "\n",
        "            # JSON ë ˆì´ë¸” ë¡œë“œ\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" ë°ì´í„°ì…‹ì—ì„œ idx ë²ˆì§¸ ìƒ˜í”Œ(ì´ë¯¸ì§€ & ë ˆì´ë¸”)ì„ ê°€ì ¸ì˜¤ëŠ” ì—­í•  \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ILAmvlWzaaO_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. ì´ë¯¸ì§€ ì „ì²˜ë¦¬: í¬ê¸° ì¡°ì •, ì •ê·œí™”"
      ],
      "metadata": {
        "id": "DYVGt8R27tXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 28x28ë¡œ ì¡°ì •\n",
        "    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "    transforms.Normalize((0.5,), (0.5,))  # ì •ê·œí™”: í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5\n",
        "])"
      ],
      "metadata": {
        "id": "X7HxQagK7vJ3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• "
      ],
      "metadata": {
        "id": "ugSpuxB27va_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train // test\n",
        "train_img_paths, test_img_paths, train_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    image_paths,\n",
        "    label_paths,\n",
        "    test_size=0.2,  # 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ\n",
        "    random_state=42  # ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥\n",
        ")\n",
        "\n",
        "# test // val\n",
        "val_img_paths, test_img_paths, val_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    test_img_paths,\n",
        "    test_lbl_paths,\n",
        "    test_size=0.5,  # 20% ì¤‘ 50%ë¥¼ ê²€ì¦ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ë¯€ë¡œ, ì „ì²´ ë°ì´í„°ì˜ 10%ê°€ ê²€ì¦ ì„¸íŠ¸ë¡œ\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±\n",
        "train_dataset = TTTDataset(train_img_paths, train_lbl_paths, transform=transform)\n",
        "val_dataset = TTTDataset(val_img_paths, val_lbl_paths, transform=transform)\n",
        "test_dataset = TTTDataset(test_img_paths, test_lbl_paths, transform=transform)\n",
        "\n",
        "'''\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "C5PlAG2P70N6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "69a27073-b4aa-41ce-d953-d86f55649412"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image_paths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-042783a69214>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_img_paths, test_img_paths, train_lbl_paths, test_lbl_paths = train_test_split(\n\u001b[1;32m      5\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
          ]
        }
      ]
    }
  ]
}