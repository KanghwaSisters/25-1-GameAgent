{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ë”¥ëŸ¬ë‹ ì‹¤ìŠµ ê³¼ì œ 1ì£¼ì°¨ - ë°ì´í„° ì „ì²˜ë¦¬\n",
        "\n",
        "ë‹¤ìŒ ì„¸ ê°€ì§€ í™œë™ì„ í•´ë´…ì‹œë‹¤.\n",
        "\n",
        "01. **ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ**: JSON íŒŒì¼ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PyTorch Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "02. **ì´ë¯¸ì§€ ì „ì²˜ë¦¬**: í¬ê¸° ì¡°ì •, ì •ê·œí™”\n",
        "03. **í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• **\n"
      ],
      "metadata": {
        "id": "_vECysj7UNoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTTDataset.zipì„ ë¶ˆëŸ¬ì™€ ë¬¸ì œì—ì„œ ìš”í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
        "\n",
        "ğŸ’¡ **ë°ì´í„° êµ¬ì¡°**  \n",
        "- **`image_black`** : ì´ë¯¸ì§€ ë°ì´í„°  \n",
        "- **`labels`** : íƒ€ê²Ÿ ë°ì´í„°  "
      ],
      "metadata": {
        "id": "s3_fdD7Y2iY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "from torch.utils.data import random_split\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "BhRH2q-fV8lc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXA2xQEjuvp8",
        "outputId": "f0c71f8e-9114-4776-f772-7b1c23c54633"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jSCz3eLuxWWO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. í´ë˜ìŠ¤\n",
        "ì •ì˜í•œ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ì‹¤í–‰í•´ ì£¼ì„¸ìš”."
      ],
      "metadata": {
        "id": "MCpJfLtnagvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/My Drive/KHS/TTTDataset/image_black'\n",
        "label_dir = '/content/drive/My Drive/KHS/TTTDataset/labels'\n",
        "\n",
        "image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")) +\n",
        "                     glob.glob(os.path.join(image_dir, \"*.JPG\")))\n",
        "label_paths = sorted(glob.glob(os.path.join(label_dir, \"*.json\")))\n",
        "\n",
        "print(f\"ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(image_paths)}\")\n",
        "print(f\"ë¼ë²¨ íŒŒì¼ ìˆ˜: {len(label_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KdpN0TVwjVX",
        "outputId": "3c3383bd-15a1-48f9-8604-54219bdca109"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: 453\n",
            "ë¼ë²¨ íŒŒì¼ ìˆ˜: 453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        \"\"\"\n",
        "        í‹±íƒí†  ë°ì´í„°ì…‹ì„ PyTorch Dataset í˜•íƒœë¡œ ë³€í™˜.\n",
        "        :param image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param label_paths: ë ˆì´ë¸” JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        :param transform: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.data = self._load_data()\n",
        "\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # ì´ë¯¸ì§€ë¥¼ í‘ë°±(Grayscale)ë¡œ ë³€í™˜\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" ëŒ€ì‹  \"L\" ì‚¬ìš©\n",
        "\n",
        "            # JSON ë ˆì´ë¸” ë¡œë“œ\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" ë°ì´í„°ì…‹ í¬ê¸° ë°˜í™˜ \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" ë°ì´í„°ì…‹ì—ì„œ idx ë²ˆì§¸ ìƒ˜í”Œ(ì´ë¯¸ì§€ & ë ˆì´ë¸”)ì„ ê°€ì ¸ì˜¤ëŠ” ì—­í•  \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Ymwd8gfCYHiq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ: JSON íŒŒì¼ê³¼ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PyTorch Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜"
      ],
      "metadata": {
        "id": "seQgBNd9aZNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "\n",
        "      self.image_paths = image_paths\n",
        "      self.label_paths = label_paths\n",
        "      self.transform = transform\n",
        "      self.data = self._load_data()\n",
        "\n",
        "    def get_image_paths(image_dir):\n",
        "      valid_extentions = ('.jpg', '.JPG')\n",
        "      image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(valid_extentions)]\n",
        "      return image_paths\n",
        "\n",
        "    def get_label_paths(label_dir):\n",
        "      valid_extentions = ('.json')\n",
        "      label_paths = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(valid_extentions)]\n",
        "      return label_paths\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" ì´ë¯¸ì§€ & ë ˆì´ë¸” ë¡œë“œ \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # ì´ë¯¸ì§€ë¥¼ í‘ë°±(Grayscale)ë¡œ ë³€í™˜\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" ëŒ€ì‹  \"L\" ì‚¬ìš©\n",
        "\n",
        "            # JSON ë ˆì´ë¸” ë¡œë“œ\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # ë ˆì´ë¸”ì„ ìˆ«ìë¡œ ë³€í™˜ (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" ë°ì´í„°ì…‹ì—ì„œ idx ë²ˆì§¸ ìƒ˜í”Œ(ì´ë¯¸ì§€ & ë ˆì´ë¸”)ì„ ê°€ì ¸ì˜¤ëŠ” ì—­í•  \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ILAmvlWzaaO_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. ì´ë¯¸ì§€ ì „ì²˜ë¦¬: í¬ê¸° ì¡°ì •, ì •ê·œí™”"
      ],
      "metadata": {
        "id": "DYVGt8R27tXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 28x28ë¡œ ì¡°ì •\n",
        "    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "    transforms.Normalize((0.5,), (0.5,))  # ì •ê·œí™”: í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5\n",
        "])"
      ],
      "metadata": {
        "id": "X7HxQagK7vJ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• "
      ],
      "metadata": {
        "id": "ugSpuxB27va_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset ìƒì„±\n",
        "dataset = TTTDataset(image_paths, label_paths, transform=transform)\n",
        "\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7*total_size)\n",
        "val_size = int(0.15*total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# ë¶„í• \n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb-ALTzmxOVu",
        "outputId": "fb593afd-bd4f-43e6-c76b-69d3cf53b612"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 317\n",
            "Validation dataset size: 67\n",
            "Test dataset size: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train // test\n",
        "train_img_paths, test_img_paths, train_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    image_paths,\n",
        "    label_paths,\n",
        "    test_size=0.2,  # 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ\n",
        "    random_state=42  # ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥\n",
        ")\n",
        "\n",
        "# test // val\n",
        "val_img_paths, test_img_paths, val_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    test_img_paths,\n",
        "    test_lbl_paths,\n",
        "    test_size=0.5,  # 20% ì¤‘ 50%ë¥¼ ê²€ì¦ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ë¯€ë¡œ, ì „ì²´ ë°ì´í„°ì˜ 10%ê°€ ê²€ì¦ ì„¸íŠ¸ë¡œ\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±\n",
        "train_dataset = TTTDataset(train_img_paths, train_lbl_paths, transform=transform)\n",
        "val_dataset = TTTDataset(val_img_paths, val_lbl_paths, transform=transform)\n",
        "test_dataset = TTTDataset(test_img_paths, test_lbl_paths, transform=transform)\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "C5PlAG2P70N6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a905dcb0-035a-404d-f144-9f8cf5472df7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 362\n",
            "Validation dataset size: 45\n",
            "Test dataset size: 46\n"
          ]
        }
      ]
    }
  ]
}