{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 딥러닝 실습 과제 1주차 - 데이터 전처리\n",
        "\n",
        "다음 세 가지 활동을 해봅시다.\n",
        "\n",
        "01. **이미지 & 레이블 로드**: JSON 파일과 이미지 데이터를 PyTorch Dataset 형식으로 변환\n",
        "02. **이미지 전처리**: 크기 조정, 정규화\n",
        "03. **학습/검증/테스트 데이터 분할**\n"
      ],
      "metadata": {
        "id": "_vECysj7UNoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTTDataset.zip을 불러와 문제에서 요하는 코드를 구현하세요.\n",
        "\n",
        "💡 **데이터 구조**  \n",
        "- **`image_black`** : 이미지 데이터  \n",
        "- **`labels`** : 타겟 데이터  "
      ],
      "metadata": {
        "id": "s3_fdD7Y2iY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "from torch.utils.data import random_split\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "BhRH2q-fV8lc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXA2xQEjuvp8",
        "outputId": "f0c71f8e-9114-4776-f772-7b1c23c54633"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jSCz3eLuxWWO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. 클래스\n",
        "정의한 클래스를 이용해 실행해 주세요."
      ],
      "metadata": {
        "id": "MCpJfLtnagvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/My Drive/KHS/TTTDataset/image_black'\n",
        "label_dir = '/content/drive/My Drive/KHS/TTTDataset/labels'\n",
        "\n",
        "image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")) +\n",
        "                     glob.glob(os.path.join(image_dir, \"*.JPG\")))\n",
        "label_paths = sorted(glob.glob(os.path.join(label_dir, \"*.json\")))\n",
        "\n",
        "print(f\"이미지 파일 수: {len(image_paths)}\")\n",
        "print(f\"라벨 파일 수: {len(label_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KdpN0TVwjVX",
        "outputId": "3c3383bd-15a1-48f9-8604-54219bdca109"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 파일 수: 453\n",
            "라벨 파일 수: 453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        \"\"\"\n",
        "        틱택토 데이터셋을 PyTorch Dataset 형태로 변환.\n",
        "        :param image_paths: 이미지 파일 경로 리스트\n",
        "        :param label_paths: 레이블 JSON 파일 경로 리스트\n",
        "        :param transform: 이미지 전처리 변환\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "        self.data = self._load_data()\n",
        "\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" 이미지 & 레이블 로드 \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # 이미지를 흑백(Grayscale)로 변환\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" 대신 \"L\" 사용\n",
        "\n",
        "            # JSON 레이블 로드\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # 레이블을 숫자로 변환 (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" 데이터셋 크기 반환 \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" 데이터셋에서 idx 번째 샘플(이미지 & 레이블)을 가져오는 역할 \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Ymwd8gfCYHiq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 이미지 & 레이블 로드: JSON 파일과 이미지 데이터를 PyTorch Dataset 형식으로 변환"
      ],
      "metadata": {
        "id": "seQgBNd9aZNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TTTDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "\n",
        "      self.image_paths = image_paths\n",
        "      self.label_paths = label_paths\n",
        "      self.transform = transform\n",
        "      self.data = self._load_data()\n",
        "\n",
        "    def get_image_paths(image_dir):\n",
        "      valid_extentions = ('.jpg', '.JPG')\n",
        "      image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(valid_extentions)]\n",
        "      return image_paths\n",
        "\n",
        "    def get_label_paths(label_dir):\n",
        "      valid_extentions = ('.json')\n",
        "      label_paths = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(valid_extentions)]\n",
        "      return label_paths\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\" 이미지 & 레이블 로드 \"\"\"\n",
        "        data = []\n",
        "        for img_path, lbl_path in zip(self.image_paths, self.label_paths):\n",
        "            # 이미지를 흑백(Grayscale)로 변환\n",
        "            image = Image.open(img_path).convert(\"L\")  # \"RGB\" 대신 \"L\" 사용\n",
        "\n",
        "            # JSON 레이블 로드\n",
        "            with open(lbl_path, 'r') as f:\n",
        "                labels = json.load(f)\n",
        "\n",
        "            # 레이블을 숫자로 변환 (O=1, X=-1, blank=0)\n",
        "            label_tensor = torch.tensor(\n",
        "                [1 if v == \"O\" else -1 if v == \"X\" else 0 for v in labels.values()],\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            data.append((image, label_tensor))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" 데이터셋에서 idx 번째 샘플(이미지 & 레이블)을 가져오는 역할 \"\"\"\n",
        "        image, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "ILAmvlWzaaO_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 이미지 전처리: 크기 조정, 정규화"
      ],
      "metadata": {
        "id": "DYVGt8R27tXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # 이미지 크기를 28x28로 조정\n",
        "    transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화: 평균 0.5, 표준편차 0.5\n",
        "])"
      ],
      "metadata": {
        "id": "X7HxQagK7vJ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 학습/검증/테스트 데이터 분할"
      ],
      "metadata": {
        "id": "ugSpuxB27va_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 생성\n",
        "dataset = TTTDataset(image_paths, label_paths, transform=transform)\n",
        "\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7*total_size)\n",
        "val_size = int(0.15*total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# 분할\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb-ALTzmxOVu",
        "outputId": "fb593afd-bd4f-43e6-c76b-69d3cf53b612"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 317\n",
            "Validation dataset size: 67\n",
            "Test dataset size: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train // test\n",
        "train_img_paths, test_img_paths, train_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    image_paths,\n",
        "    label_paths,\n",
        "    test_size=0.2,  # 20%를 테스트 세트로\n",
        "    random_state=42  # 랜덤 시드를 고정하여 결과 재현 가능\n",
        ")\n",
        "\n",
        "# test // val\n",
        "val_img_paths, test_img_paths, val_lbl_paths, test_lbl_paths = train_test_split(\n",
        "    test_img_paths,\n",
        "    test_lbl_paths,\n",
        "    test_size=0.5,  # 20% 중 50%를 검증 세트로 나누므로, 전체 데이터의 10%가 검증 세트로\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 데이터셋 객체 생성\n",
        "train_dataset = TTTDataset(train_img_paths, train_lbl_paths, transform=transform)\n",
        "val_dataset = TTTDataset(val_img_paths, val_lbl_paths, transform=transform)\n",
        "test_dataset = TTTDataset(test_img_paths, test_lbl_paths, transform=transform)\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "C5PlAG2P70N6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a905dcb0-035a-404d-f144-9f8cf5472df7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 362\n",
            "Validation dataset size: 45\n",
            "Test dataset size: 46\n"
          ]
        }
      ]
    }
  ]
}